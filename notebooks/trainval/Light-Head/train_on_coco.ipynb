{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Light-Head Mask-RCNN on the Coco Dataset\n",
    "This notebook provides a fast way to start training on Coco dataset based on Light-Head Mask-RCNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Based on the work of Waleed Abdulla (Matterport)\n",
    "written by wozhouh\n",
    "\"\"\"\n",
    "\n",
    "# Import Python Packages\n",
    "import os\n",
    "import imgaug\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"../../../\")\n",
    "import sys\n",
    "\n",
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)\n",
    "from mrcnn import model as modellib\n",
    "\n",
    "# Import COCO config\n",
    "sys.path.append(os.path.join(ROOT_DIR, \"samples\", \"coco\"))  # To find local version\n",
    "import coco\n",
    "\n",
    "# # assign the GPU for training\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default setting\n",
    "HOME_DIR = os.getenv('HOME')\n",
    "DEFAULT_WEIGHTS_DIR = os.path.join(ROOT_DIR, \"weights\")\n",
    "DEFAULT_LOGS_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "DEFAULT_DATASET_YEAR = \"2017\"\n",
    "DEFAULT_COCO_PATH = os.path.join(HOME_DIR, \"data\", \"Coco\")\n",
    "\n",
    "# weights to load\n",
    "# MODEL_PATH_UNDER_HOME = os.path.join(DEFAULT_WEIGHTS_DIR, \"ResNet-101\", \"mask_rcnn_coco.h5\")\n",
    "MODEL_PATH_UNDER_HOME = os.path.join(DEFAULT_LOGS_DIR, \"Light-Head\", \"training20181211T1752\", \"mask_rcnn_training_0243.h5\")\n",
    "INIT_MODEL_PATH = os.path.join(HOME_DIR, MODEL_PATH_UNDER_HOME)\n",
    "LOG_DIR = os.path.join(DEFAULT_LOGS_DIR, \"Light-Head\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     4\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_HEAD                 light-head\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     2048\n",
      "GPU_COUNT                      2\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 2\n",
      "IMAGE_CHANNEL_COUNT            3\n",
      "IMAGE_MAX_DIM                  1024\n",
      "IMAGE_META_SIZE                93\n",
      "IMAGE_MIN_DIM                  800\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [1024 1024    3]\n",
      "LARGE_SEPARABLE_CHANNELS_MID   256\n",
      "LARGE_SEPARABLE_CHANNELS_OUT   490\n",
      "LARGE_SEPARABLE_KERNEL_SIZE    15\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 0.0, 'rpn_bbox_loss': 0.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.5, 'mrcnn_mask_loss': 0.0}\n",
      "MASK_HEAD                      original\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           training\n",
      "NUM_CLASSES                    81\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "PRE_NMS_LIMIT                  6000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                1000\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           200\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               50\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# training config\n",
    "class TrainingConfig(coco.CocoConfig):\n",
    "    NAME = \"training\"\n",
    "    \n",
    "    # GPU\n",
    "    # Set batch size to 1 since we'll be running inference on\n",
    "    # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU\n",
    "    GPU_COUNT = 2\n",
    "    IMAGES_PER_GPU = 2\n",
    "    \n",
    "    # data\n",
    "    IMAGE_MIN_DIM = 800\n",
    "    IMAGE_MAX_DIM = 1024\n",
    "    RPN_ANCHOR_SCALES = (32, 64, 128, 256, 512)\n",
    "    \n",
    "    # model\n",
    "    BACKBONE = \"resnet101\"\n",
    "    BACKBONE_STRIDES = [4, 8, 16, 32, 64]\n",
    "    \n",
    "    # heads\n",
    "    TOP_DOWN_PYRAMID_SIZE = 256\n",
    "    DETECTION_HEAD = \"light-head\" \n",
    "    MASK_HEAD = \"original\"\n",
    "    FPN_CLASSIF_FC_LAYERS_SIZE = 2048\n",
    "    RPN_TRAIN_ANCHORS_PER_IMAGE = 256\n",
    "    LARGE_SEPARABLE_KERNEL_SIZE = 15\n",
    "    LARGE_SEPARABLE_CHANNELS_MID = 256\n",
    "    LARGE_SEPARABLE_CHANNELS_OUT = 490\n",
    "    \n",
    "    # training\n",
    "    LEARNING_RATE = 0.001\n",
    "    WEIGHT_DECAY = 0.0001\n",
    "#     LOSS_WEIGHTS = {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
    "    LOSS_WEIGHTS = {'rpn_class_loss': 0.0, 'rpn_bbox_loss': 0.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.5, 'mrcnn_mask_loss': 0.0}\n",
    "    STEPS_PER_EPOCH = 1000\n",
    "    VALIDATION_STEPS = 50\n",
    "    TRAIN_BN = False\n",
    "    TRAIN_ROIS_PER_IMAGE = 200\n",
    "    ROI_POSITIVE_RATIO = 0.33\n",
    "    \n",
    "config = TrainingConfig()\n",
    "config.display()\n",
    "model = modellib.MaskRCNN(mode=\"training\", model_dir=LOG_DIR, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_image (InputLayer)        (None, None, None, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_image_meta (InputLayer)   (None, 93)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_rpn_match (InputLayer)    (None, None, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_rpn_bbox (InputLayer)     (None, None, 4)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_gt_class_ids (InputLayer) (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_gt_boxes (InputLayer)     (None, None, 4)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_gt_masks (InputLayer)     (None, 56, 56, None) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, None, None, 3 0           input_image[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 93)           0           input_image_meta[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, None, 1)      0           input_rpn_match[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, None, 4)      0           input_rpn_bbox[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, None)         0           input_gt_class_ids[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)              (None, None, 4)      0           input_gt_boxes[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)              (None, 56, 56, None) 0           input_gt_masks[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lambda_12 (Lambda)              (None, None, None, 3 0           input_image[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_13 (Lambda)              (None, 93)           0           input_image_meta[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_14 (Lambda)              (None, None, 1)      0           input_rpn_match[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_15 (Lambda)              (None, None, 4)      0           input_rpn_bbox[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lambda_16 (Lambda)              (None, None)         0           input_gt_class_ids[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "lambda_17 (Lambda)              (None, None, 4)      0           input_gt_boxes[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lambda_18 (Lambda)              (None, 56, 56, None) 0           input_gt_masks[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "mask_rcnn (Model)               [(None, None, 2), (N 57415924    lambda_5[0][0]                   \n",
      "                                                                 lambda_6[0][0]                   \n",
      "                                                                 lambda_7[0][0]                   \n",
      "                                                                 lambda_8[0][0]                   \n",
      "                                                                 lambda_9[0][0]                   \n",
      "                                                                 lambda_10[0][0]                  \n",
      "                                                                 lambda_11[0][0]                  \n",
      "                                                                 lambda_12[0][0]                  \n",
      "                                                                 lambda_13[0][0]                  \n",
      "                                                                 lambda_14[0][0]                  \n",
      "                                                                 lambda_15[0][0]                  \n",
      "                                                                 lambda_16[0][0]                  \n",
      "                                                                 lambda_17[0][0]                  \n",
      "                                                                 lambda_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "rpn_class_logits (Concatenate)  (None, None, 2)      0           mask_rcnn[1][0]                  \n",
      "                                                                 mask_rcnn[2][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "rpn_class (Concatenate)         (None, None, 2)      0           mask_rcnn[1][1]                  \n",
      "                                                                 mask_rcnn[2][1]                  \n",
      "__________________________________________________________________________________________________\n",
      "rpn_bbox (Concatenate)          (None, None, 4)      0           mask_rcnn[1][2]                  \n",
      "                                                                 mask_rcnn[2][2]                  \n",
      "__________________________________________________________________________________________________\n",
      "light_head_class_logits (Concat (None, 200, 81)      0           mask_rcnn[1][3]                  \n",
      "                                                                 mask_rcnn[2][3]                  \n",
      "__________________________________________________________________________________________________\n",
      "light_head_class (Concatenate)  (None, 200, 81)      0           mask_rcnn[1][4]                  \n",
      "                                                                 mask_rcnn[2][4]                  \n",
      "__________________________________________________________________________________________________\n",
      "light_head_bbox (Concatenate)   (None, 200, 81, 4)   0           mask_rcnn[1][5]                  \n",
      "                                                                 mask_rcnn[2][5]                  \n",
      "__________________________________________________________________________________________________\n",
      "mrcnn_mask (Concatenate)        (None, 200, 28, 28,  0           mask_rcnn[1][6]                  \n",
      "                                                                 mask_rcnn[2][6]                  \n",
      "__________________________________________________________________________________________________\n",
      "ROI (Concatenate)               (None, 2000, 4)      0           mask_rcnn[1][7]                  \n",
      "                                                                 mask_rcnn[2][7]                  \n",
      "__________________________________________________________________________________________________\n",
      "output_rois (Concatenate)       (None, 200, 4)       0           mask_rcnn[1][8]                  \n",
      "                                                                 mask_rcnn[2][8]                  \n",
      "__________________________________________________________________________________________________\n",
      "rpn_class_loss (Lambda)         ()                   0           mask_rcnn[1][9]                  \n",
      "                                                                 mask_rcnn[2][9]                  \n",
      "__________________________________________________________________________________________________\n",
      "rpn_bbox_loss (Lambda)          ()                   0           mask_rcnn[1][10]                 \n",
      "                                                                 mask_rcnn[2][10]                 \n",
      "__________________________________________________________________________________________________\n",
      "mrcnn_class_loss (Lambda)       ()                   0           mask_rcnn[1][11]                 \n",
      "                                                                 mask_rcnn[2][11]                 \n",
      "__________________________________________________________________________________________________\n",
      "mrcnn_bbox_loss (Lambda)        ()                   0           mask_rcnn[1][12]                 \n",
      "                                                                 mask_rcnn[2][12]                 \n",
      "__________________________________________________________________________________________________\n",
      "mrcnn_mask_loss (Lambda)        ()                   0           mask_rcnn[1][13]                 \n",
      "                                                                 mask_rcnn[2][13]                 \n",
      "==================================================================================================\n",
      "Total params: 57,415,924\n",
      "Trainable params: 57,303,456\n",
      "Non-trainable params: 112,468\n",
      "__________________________________________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_image (InputLayer)        (None, None, None, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D (None, None, None, 3 0           input_image[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, None, None, 6 9472        zero_padding2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNorm)            (None, None, None, 6 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, None, None, 6 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, None, None, 6 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, None, None, 6 4160        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNorm)       (None, None, None, 6 256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, None, None, 6 0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, None, None, 6 36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNorm)       (None, None, None, 6 256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, None, None, 6 0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, None, None, 2 16640       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, None, None, 2 16640       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNorm)       (None, None, None, 2 1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNorm)        (None, None, None, 2 1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, None, None, 2 0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_out (Activation)          (None, None, None, 2 0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, None, None, 6 16448       res2a_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNorm)       (None, None, None, 6 256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, None, None, 6 0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, None, None, 6 36928       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNorm)       (None, None, None, 6 256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, None, None, 6 0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, None, None, 2 16640       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNorm)       (None, None, None, 2 1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, None, None, 2 0           bn2b_branch2c[0][0]              \n",
      "                                                                 res2a_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2b_out (Activation)          (None, None, None, 2 0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, None, None, 6 16448       res2b_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNorm)       (None, None, None, 6 256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, None, None, 6 0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, None, None, 6 36928       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNorm)       (None, None, None, 6 256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, None, None, 6 0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, None, None, 2 16640       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNorm)       (None, None, None, 2 1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, None, None, 2 0           bn2c_branch2c[0][0]              \n",
      "                                                                 res2b_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2c_out (Activation)          (None, None, None, 2 0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, None, None, 1 32896       res2c_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNorm)       (None, None, None, 1 512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, None, None, 1 0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, None, None, 1 147584      activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNorm)       (None, None, None, 1 512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, None, None, 1 0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, None, None, 5 66048       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, None, None, 5 131584      res2c_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNorm)       (None, None, None, 5 2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNorm)        (None, None, None, 5 2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, None, None, 5 0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res3a_out (Activation)          (None, None, None, 5 0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, None, None, 1 65664       res3a_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNorm)       (None, None, None, 1 512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, None, None, 1 0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, None, None, 1 147584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNorm)       (None, None, None, 1 512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, None, None, 1 0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, None, None, 5 66048       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNorm)       (None, None, None, 5 2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, None, None, 5 0           bn3b_branch2c[0][0]              \n",
      "                                                                 res3a_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res3b_out (Activation)          (None, None, None, 5 0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, None, None, 1 65664       res3b_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNorm)       (None, None, None, 1 512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, None, None, 1 0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, None, None, 1 147584      activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNorm)       (None, None, None, 1 512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, None, None, 1 0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, None, None, 5 66048       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNorm)       (None, None, None, 5 2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, None, None, 5 0           bn3c_branch2c[0][0]              \n",
      "                                                                 res3b_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res3c_out (Activation)          (None, None, None, 5 0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, None, None, 1 65664       res3c_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNorm)       (None, None, None, 1 512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, None, None, 1 0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, None, None, 1 147584      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNorm)       (None, None, None, 1 512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, None, None, 1 0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, None, None, 5 66048       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNorm)       (None, None, None, 5 2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, None, None, 5 0           bn3d_branch2c[0][0]              \n",
      "                                                                 res3c_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res3d_out (Activation)          (None, None, None, 5 0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, None, None, 2 131328      res3d_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNorm)       (None, None, None, 2 1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, None, None, 2 0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, None, None, 2 590080      activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNorm)       (None, None, None, 2 1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, None, None, 2 0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, None, None, 1 263168      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, None, None, 1 525312      res3d_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNorm)       (None, None, None, 1 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNorm)        (None, None, None, 1 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, None, None, 1 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res4a_out (Activation)          (None, None, None, 1 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, None, None, 2 262400      res4a_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNorm)       (None, None, None, 2 1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, None, None, 2 0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, None, None, 2 590080      activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNorm)       (None, None, None, 2 1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, None, None, 2 0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, None, None, 1 263168      activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNorm)       (None, None, None, 1 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, None, None, 1 0           bn4b_branch2c[0][0]              \n",
      "                                                                 res4a_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res4b_out (Activation)          (None, None, None, 1 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, None, None, 2 262400      res4b_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNorm)       (None, None, None, 2 1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, None, None, 2 0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, None, None, 2 590080      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNorm)       (None, None, None, 2 1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, None, None, 2 0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, None, None, 1 263168      activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNorm)       (None, None, None, 1 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, None, None, 1 0           bn4c_branch2c[0][0]              \n",
      "                                                                 res4b_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res4c_out (Activation)          (None, None, None, 1 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, None, None, 2 262400      res4c_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNorm)       (None, None, None, 2 1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, None, None, 2 0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, None, None, 2 590080      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNorm)       (None, None, None, 2 1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, None, None, 2 0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, None, None, 1 263168      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNorm)       (None, None, None, 1 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, None, None, 1 0           bn4d_branch2c[0][0]              \n",
      "                                                                 res4c_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res4d_out (Activation)          (None, None, None, 1 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, None, None, 2 262400      res4d_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNorm)       (None, None, None, 2 1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, None, None, 2 0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, None, None, 2 590080      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNorm)       (None, None, None, 2 1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, None, None, 2 0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, None, None, 1 263168      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNorm)       (None, None, None, 1 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, None, None, 1 0           bn4e_branch2c[0][0]              \n",
      "                                                                 res4d_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res4e_out (Activation)          (None, None, None, 1 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, None, None, 2 262400      res4e_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNorm)       (None, None, None, 2 1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, None, None, 2 0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, None, None, 2 590080      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNorm)       (None, None, None, 2 1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, None, None, 2 0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, None, None, 1 263168      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNorm)       (None, None, None, 1 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, None, None, 1 0           bn4f_branch2c[0][0]              \n",
      "                                                                 res4e_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res4f_out (Activation)          (None, None, None, 1 0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4g_branch2a (Conv2D)         (None, None, None, 2 262400      res4f_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn4g_branch2a (BatchNorm)       (None, None, None, 2 1024        res4g_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, None, None, 2 0           bn4g_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4g_branch2b (Conv2D)         (None, None, None, 2 590080      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4g_branch2b (BatchNorm)       (None, None, None, 2 1024        res4g_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, None, None, 2 0           bn4g_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4g_branch2c (Conv2D)         (None, None, None, 1 263168      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4g_branch2c (BatchNorm)       (None, None, None, 1 4096        res4g_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, None, None, 1 0           bn4g_branch2c[0][0]              \n",
      "                                                                 res4f_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res4g_out (Activation)          (None, None, None, 1 0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4h_branch2a (Conv2D)         (None, None, None, 2 262400      res4g_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn4h_branch2a (BatchNorm)       (None, None, None, 2 1024        res4h_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, None, None, 2 0           bn4h_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4h_branch2b (Conv2D)         (None, None, None, 2 590080      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4h_branch2b (BatchNorm)       (None, None, None, 2 1024        res4h_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, None, None, 2 0           bn4h_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4h_branch2c (Conv2D)         (None, None, None, 1 263168      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4h_branch2c (BatchNorm)       (None, None, None, 1 4096        res4h_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, None, None, 1 0           bn4h_branch2c[0][0]              \n",
      "                                                                 res4g_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res4h_out (Activation)          (None, None, None, 1 0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4i_branch2a (Conv2D)         (None, None, None, 2 262400      res4h_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn4i_branch2a (BatchNorm)       (None, None, None, 2 1024        res4i_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, None, None, 2 0           bn4i_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4i_branch2b (Conv2D)         (None, None, None, 2 590080      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4i_branch2b (BatchNorm)       (None, None, None, 2 1024        res4i_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, None, None, 2 0           bn4i_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4i_branch2c (Conv2D)         (None, None, None, 1 263168      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4i_branch2c (BatchNorm)       (None, None, None, 1 4096        res4i_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, None, None, 1 0           bn4i_branch2c[0][0]              \n",
      "                                                                 res4h_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res4i_out (Activation)          (None, None, None, 1 0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4j_branch2a (Conv2D)         (None, None, None, 2 262400      res4i_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn4j_branch2a (BatchNorm)       (None, None, None, 2 1024        res4j_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, None, None, 2 0           bn4j_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4j_branch2b (Conv2D)         (None, None, None, 2 590080      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4j_branch2b (BatchNorm)       (None, None, None, 2 1024        res4j_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, None, None, 2 0           bn4j_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4j_branch2c (Conv2D)         (None, None, None, 1 263168      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4j_branch2c (BatchNorm)       (None, None, None, 1 4096        res4j_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, None, None, 1 0           bn4j_branch2c[0][0]              \n",
      "                                                                 res4i_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res4j_out (Activation)          (None, None, None, 1 0           add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4k_branch2a (Conv2D)         (None, None, None, 2 262400      res4j_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn4k_branch2a (BatchNorm)       (None, None, None, 2 1024        res4k_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, None, None, 2 0           bn4k_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4k_branch2b (Conv2D)         (None, None, None, 2 590080      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4k_branch2b (BatchNorm)       (None, None, None, 2 1024        res4k_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, None, None, 2 0           bn4k_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4k_branch2c (Conv2D)         (None, None, None, 1 263168      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4k_branch2c (BatchNorm)       (None, None, None, 1 4096        res4k_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, None, None, 1 0           bn4k_branch2c[0][0]              \n",
      "                                                                 res4j_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res4k_out (Activation)          (None, None, None, 1 0           add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4l_branch2a (Conv2D)         (None, None, None, 2 262400      res4k_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn4l_branch2a (BatchNorm)       (None, None, None, 2 1024        res4l_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, None, None, 2 0           bn4l_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4l_branch2b (Conv2D)         (None, None, None, 2 590080      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4l_branch2b (BatchNorm)       (None, None, None, 2 1024        res4l_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, None, None, 2 0           bn4l_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4l_branch2c (Conv2D)         (None, None, None, 1 263168      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4l_branch2c (BatchNorm)       (None, None, None, 1 4096        res4l_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, None, None, 1 0           bn4l_branch2c[0][0]              \n",
      "                                                                 res4k_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res4l_out (Activation)          (None, None, None, 1 0           add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4m_branch2a (Conv2D)         (None, None, None, 2 262400      res4l_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn4m_branch2a (BatchNorm)       (None, None, None, 2 1024        res4m_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, None, None, 2 0           bn4m_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4m_branch2b (Conv2D)         (None, None, None, 2 590080      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4m_branch2b (BatchNorm)       (None, None, None, 2 1024        res4m_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, None, None, 2 0           bn4m_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4m_branch2c (Conv2D)         (None, None, None, 1 263168      activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4m_branch2c (BatchNorm)       (None, None, None, 1 4096        res4m_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, None, None, 1 0           bn4m_branch2c[0][0]              \n",
      "                                                                 res4l_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res4m_out (Activation)          (None, None, None, 1 0           add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4n_branch2a (Conv2D)         (None, None, None, 2 262400      res4m_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn4n_branch2a (BatchNorm)       (None, None, None, 2 1024        res4n_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, None, None, 2 0           bn4n_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4n_branch2b (Conv2D)         (None, None, None, 2 590080      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4n_branch2b (BatchNorm)       (None, None, None, 2 1024        res4n_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, None, None, 2 0           bn4n_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4n_branch2c (Conv2D)         (None, None, None, 1 263168      activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4n_branch2c (BatchNorm)       (None, None, None, 1 4096        res4n_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, None, None, 1 0           bn4n_branch2c[0][0]              \n",
      "                                                                 res4m_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res4n_out (Activation)          (None, None, None, 1 0           add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4o_branch2a (Conv2D)         (None, None, None, 2 262400      res4n_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn4o_branch2a (BatchNorm)       (None, None, None, 2 1024        res4o_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, None, None, 2 0           bn4o_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4o_branch2b (Conv2D)         (None, None, None, 2 590080      activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4o_branch2b (BatchNorm)       (None, None, None, 2 1024        res4o_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, None, None, 2 0           bn4o_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4o_branch2c (Conv2D)         (None, None, None, 1 263168      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4o_branch2c (BatchNorm)       (None, None, None, 1 4096        res4o_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, None, None, 1 0           bn4o_branch2c[0][0]              \n",
      "                                                                 res4n_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res4o_out (Activation)          (None, None, None, 1 0           add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4p_branch2a (Conv2D)         (None, None, None, 2 262400      res4o_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn4p_branch2a (BatchNorm)       (None, None, None, 2 1024        res4p_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, None, None, 2 0           bn4p_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4p_branch2b (Conv2D)         (None, None, None, 2 590080      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4p_branch2b (BatchNorm)       (None, None, None, 2 1024        res4p_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, None, None, 2 0           bn4p_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4p_branch2c (Conv2D)         (None, None, None, 1 263168      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4p_branch2c (BatchNorm)       (None, None, None, 1 4096        res4p_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_23 (Add)                    (None, None, None, 1 0           bn4p_branch2c[0][0]              \n",
      "                                                                 res4o_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res4p_out (Activation)          (None, None, None, 1 0           add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4q_branch2a (Conv2D)         (None, None, None, 2 262400      res4p_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn4q_branch2a (BatchNorm)       (None, None, None, 2 1024        res4q_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, None, None, 2 0           bn4q_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4q_branch2b (Conv2D)         (None, None, None, 2 590080      activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4q_branch2b (BatchNorm)       (None, None, None, 2 1024        res4q_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, None, None, 2 0           bn4q_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4q_branch2c (Conv2D)         (None, None, None, 1 263168      activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4q_branch2c (BatchNorm)       (None, None, None, 1 4096        res4q_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_24 (Add)                    (None, None, None, 1 0           bn4q_branch2c[0][0]              \n",
      "                                                                 res4p_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res4q_out (Activation)          (None, None, None, 1 0           add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4r_branch2a (Conv2D)         (None, None, None, 2 262400      res4q_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn4r_branch2a (BatchNorm)       (None, None, None, 2 1024        res4r_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, None, None, 2 0           bn4r_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4r_branch2b (Conv2D)         (None, None, None, 2 590080      activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4r_branch2b (BatchNorm)       (None, None, None, 2 1024        res4r_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, None, None, 2 0           bn4r_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4r_branch2c (Conv2D)         (None, None, None, 1 263168      activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4r_branch2c (BatchNorm)       (None, None, None, 1 4096        res4r_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_25 (Add)                    (None, None, None, 1 0           bn4r_branch2c[0][0]              \n",
      "                                                                 res4q_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res4r_out (Activation)          (None, None, None, 1 0           add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4s_branch2a (Conv2D)         (None, None, None, 2 262400      res4r_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn4s_branch2a (BatchNorm)       (None, None, None, 2 1024        res4s_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, None, None, 2 0           bn4s_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4s_branch2b (Conv2D)         (None, None, None, 2 590080      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4s_branch2b (BatchNorm)       (None, None, None, 2 1024        res4s_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, None, None, 2 0           bn4s_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4s_branch2c (Conv2D)         (None, None, None, 1 263168      activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4s_branch2c (BatchNorm)       (None, None, None, 1 4096        res4s_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_26 (Add)                    (None, None, None, 1 0           bn4s_branch2c[0][0]              \n",
      "                                                                 res4r_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res4s_out (Activation)          (None, None, None, 1 0           add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4t_branch2a (Conv2D)         (None, None, None, 2 262400      res4s_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn4t_branch2a (BatchNorm)       (None, None, None, 2 1024        res4t_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, None, None, 2 0           bn4t_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4t_branch2b (Conv2D)         (None, None, None, 2 590080      activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4t_branch2b (BatchNorm)       (None, None, None, 2 1024        res4t_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, None, None, 2 0           bn4t_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4t_branch2c (Conv2D)         (None, None, None, 1 263168      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4t_branch2c (BatchNorm)       (None, None, None, 1 4096        res4t_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_27 (Add)                    (None, None, None, 1 0           bn4t_branch2c[0][0]              \n",
      "                                                                 res4s_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res4t_out (Activation)          (None, None, None, 1 0           add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4u_branch2a (Conv2D)         (None, None, None, 2 262400      res4t_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn4u_branch2a (BatchNorm)       (None, None, None, 2 1024        res4u_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, None, None, 2 0           bn4u_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4u_branch2b (Conv2D)         (None, None, None, 2 590080      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4u_branch2b (BatchNorm)       (None, None, None, 2 1024        res4u_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, None, None, 2 0           bn4u_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4u_branch2c (Conv2D)         (None, None, None, 1 263168      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4u_branch2c (BatchNorm)       (None, None, None, 1 4096        res4u_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_28 (Add)                    (None, None, None, 1 0           bn4u_branch2c[0][0]              \n",
      "                                                                 res4t_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res4u_out (Activation)          (None, None, None, 1 0           add_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4v_branch2a (Conv2D)         (None, None, None, 2 262400      res4u_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn4v_branch2a (BatchNorm)       (None, None, None, 2 1024        res4v_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, None, None, 2 0           bn4v_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4v_branch2b (Conv2D)         (None, None, None, 2 590080      activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4v_branch2b (BatchNorm)       (None, None, None, 2 1024        res4v_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, None, None, 2 0           bn4v_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4v_branch2c (Conv2D)         (None, None, None, 1 263168      activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4v_branch2c (BatchNorm)       (None, None, None, 1 4096        res4v_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_29 (Add)                    (None, None, None, 1 0           bn4v_branch2c[0][0]              \n",
      "                                                                 res4u_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res4v_out (Activation)          (None, None, None, 1 0           add_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4w_branch2a (Conv2D)         (None, None, None, 2 262400      res4v_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn4w_branch2a (BatchNorm)       (None, None, None, 2 1024        res4w_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, None, None, 2 0           bn4w_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4w_branch2b (Conv2D)         (None, None, None, 2 590080      activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4w_branch2b (BatchNorm)       (None, None, None, 2 1024        res4w_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, None, None, 2 0           bn4w_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4w_branch2c (Conv2D)         (None, None, None, 1 263168      activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4w_branch2c (BatchNorm)       (None, None, None, 1 4096        res4w_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_30 (Add)                    (None, None, None, 1 0           bn4w_branch2c[0][0]              \n",
      "                                                                 res4v_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res4w_out (Activation)          (None, None, None, 1 0           add_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, None, None, 5 524800      res4w_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNorm)       (None, None, None, 5 2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, None, None, 5 0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, None, None, 5 2359808     activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNorm)       (None, None, None, 5 2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, None, None, 5 0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, None, None, 2 1050624     activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, None, None, 2 2099200     res4w_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNorm)       (None, None, None, 2 8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNorm)        (None, None, None, 2 8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_31 (Add)                    (None, None, None, 2 0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res5a_out (Activation)          (None, None, None, 2 0           add_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, None, None, 5 1049088     res5a_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNorm)       (None, None, None, 5 2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, None, None, 5 0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, None, None, 5 2359808     activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNorm)       (None, None, None, 5 2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, None, None, 5 0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, None, None, 2 1050624     activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNorm)       (None, None, None, 2 8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_32 (Add)                    (None, None, None, 2 0           bn5b_branch2c[0][0]              \n",
      "                                                                 res5a_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res5b_out (Activation)          (None, None, None, 2 0           add_32[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, None, None, 5 1049088     res5b_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNorm)       (None, None, None, 5 2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, None, None, 5 0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, None, None, 5 2359808     activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNorm)       (None, None, None, 5 2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, None, None, 5 0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, None, None, 2 1050624     activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNorm)       (None, None, None, 2 8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_33 (Add)                    (None, None, None, 2 0           bn5c_branch2c[0][0]              \n",
      "                                                                 res5b_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res5c_out (Activation)          (None, None, None, 2 0           add_33[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "fpn_c5p5 (Conv2D)               (None, None, None, 2 524544      res5c_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "fpn_p5upsampled (UpSampling2D)  (None, None, None, 2 0           fpn_c5p5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "fpn_c4p4 (Conv2D)               (None, None, None, 2 262400      res4w_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "fpn_p4add (Add)                 (None, None, None, 2 0           fpn_p5upsampled[0][0]            \n",
      "                                                                 fpn_c4p4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "fpn_p4upsampled (UpSampling2D)  (None, None, None, 2 0           fpn_p4add[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "fpn_c3p3 (Conv2D)               (None, None, None, 2 131328      res3d_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "fpn_p3add (Add)                 (None, None, None, 2 0           fpn_p4upsampled[0][0]            \n",
      "                                                                 fpn_c3p3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "fpn_p3upsampled (UpSampling2D)  (None, None, None, 2 0           fpn_p3add[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "fpn_c2p2 (Conv2D)               (None, None, None, 2 65792       res2c_out[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "fpn_p2add (Add)                 (None, None, None, 2 0           fpn_p3upsampled[0][0]            \n",
      "                                                                 fpn_c2p2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "fpn_p5 (Conv2D)                 (None, None, None, 2 590080      fpn_c5p5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "fpn_p2 (Conv2D)                 (None, None, None, 2 590080      fpn_p2add[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "fpn_p3 (Conv2D)                 (None, None, None, 2 590080      fpn_p3add[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "fpn_p4 (Conv2D)                 (None, None, None, 2 590080      fpn_p4add[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "fpn_p6 (MaxPooling2D)           (None, None, None, 2 0           fpn_p5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "rpn_model (Model)               [(None, None, 2), (N 1189394     fpn_p2[0][0]                     \n",
      "                                                                 fpn_p3[0][0]                     \n",
      "                                                                 fpn_p4[0][0]                     \n",
      "                                                                 fpn_p5[0][0]                     \n",
      "                                                                 fpn_p6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "rpn_class (Concatenate)         (None, None, 2)      0           rpn_model[1][1]                  \n",
      "                                                                 rpn_model[2][1]                  \n",
      "                                                                 rpn_model[3][1]                  \n",
      "                                                                 rpn_model[4][1]                  \n",
      "                                                                 rpn_model[5][1]                  \n",
      "__________________________________________________________________________________________________\n",
      "rpn_bbox (Concatenate)          (None, None, 4)      0           rpn_model[1][2]                  \n",
      "                                                                 rpn_model[2][2]                  \n",
      "                                                                 rpn_model[3][2]                  \n",
      "                                                                 rpn_model[4][2]                  \n",
      "                                                                 rpn_model[5][2]                  \n",
      "__________________________________________________________________________________________________\n",
      "anchors (Lambda)                (4, 261888, 4)       0           input_image[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "input_gt_boxes (InputLayer)     (None, None, 4)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ROI (ProposalLayer)             (None, 2000, 4)      0           rpn_class[0][0]                  \n",
      "                                                                 rpn_bbox[0][0]                   \n",
      "                                                                 anchors[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_gt_class_ids (InputLayer) (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, None, 4)      0           input_gt_boxes[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "input_gt_masks (InputLayer)     (None, 56, 56, None) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "proposal_targets (DetectionTarg [(None, 200, 4), (No 0           ROI[0][0]                        \n",
      "                                                                 input_gt_class_ids[0][0]         \n",
      "                                                                 lambda_1[0][0]                   \n",
      "                                                                 input_gt_masks[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "input_image_meta (InputLayer)   (None, 93)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "roi_align_mask (PyramidROIAlign (None, 200, 14, 14,  0           proposal_targets[0][0]           \n",
      "                                                                 input_image_meta[0][0]           \n",
      "                                                                 fpn_p2[0][0]                     \n",
      "                                                                 fpn_p3[0][0]                     \n",
      "                                                                 fpn_p4[0][0]                     \n",
      "                                                                 fpn_p5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mrcnn_mask_conv1 (TimeDistribut (None, 200, 14, 14,  590080      roi_align_mask[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "mrcnn_mask_bn1 (TimeDistributed (None, 200, 14, 14,  1024        mrcnn_mask_conv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 200, 14, 14,  0           mrcnn_mask_bn1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "mrcnn_mask_conv2 (TimeDistribut (None, 200, 14, 14,  590080      activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "mrcnn_mask_bn2 (TimeDistributed (None, 200, 14, 14,  1024        mrcnn_mask_conv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 200, 14, 14,  0           mrcnn_mask_bn2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "large_separable_conv (Model)    (None, None, None, 4 5732732     fpn_p2[0][0]                     \n",
      "                                                                 fpn_p3[0][0]                     \n",
      "                                                                 fpn_p4[0][0]                     \n",
      "                                                                 fpn_p5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mrcnn_mask_conv3 (TimeDistribut (None, 200, 14, 14,  590080      activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "psroi_align_classifier (Pyramid (None, 200, 7, 7, 10 0           proposal_targets[0][0]           \n",
      "                                                                 input_image_meta[0][0]           \n",
      "                                                                 large_separable_conv[1][0]       \n",
      "                                                                 large_separable_conv[2][0]       \n",
      "                                                                 large_separable_conv[3][0]       \n",
      "                                                                 large_separable_conv[4][0]       \n",
      "__________________________________________________________________________________________________\n",
      "mrcnn_mask_bn3 (TimeDistributed (None, 200, 14, 14,  1024        mrcnn_mask_conv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "light_head_class_conv (TimeDist (None, 200, 1, 1, 20 1005568     psroi_align_classifier[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 200, 14, 14,  0           mrcnn_mask_bn3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "light_head_class_bn (TimeDistri (None, 200, 1, 1, 20 8192        light_head_class_conv[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "mrcnn_mask_conv4 (TimeDistribut (None, 200, 14, 14,  590080      activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 200, 1, 1, 20 0           light_head_class_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "mrcnn_mask_bn4 (TimeDistributed (None, 200, 14, 14,  1024        mrcnn_mask_conv4[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "pool_squeeze (Lambda)           (None, 200, 2048)    0           activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 200, 14, 14,  0           mrcnn_mask_bn4[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "light_head_bbox_fc (TimeDistrib (None, 200, 324)     663876      pool_squeeze[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "mrcnn_mask_deconv (TimeDistribu (None, 200, 28, 28,  262400      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "rpn_class_logits (Concatenate)  (None, None, 2)      0           rpn_model[1][0]                  \n",
      "                                                                 rpn_model[2][0]                  \n",
      "                                                                 rpn_model[3][0]                  \n",
      "                                                                 rpn_model[4][0]                  \n",
      "                                                                 rpn_model[5][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "light_head_class_logits (TimeDi (None, 200, 81)      165969      pool_squeeze[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "light_head_bbox (Reshape)       (None, 200, 81, 4)   0           light_head_bbox_fc[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "mrcnn_mask (TimeDistributed)    (None, 200, 28, 28,  20817       mrcnn_mask_deconv[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "input_rpn_match (InputLayer)    (None, None, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_rpn_bbox (InputLayer)     (None, None, 4)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 81)           0           input_image_meta[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "light_head_class (TimeDistribut (None, 200, 81)      0           light_head_class_logits[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "output_rois (Lambda)            (None, 200, 4)       0           proposal_targets[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "rpn_class_loss (Lambda)         ()                   0           input_rpn_match[0][0]            \n",
      "                                                                 rpn_class_logits[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "rpn_bbox_loss (Lambda)          ()                   0           input_rpn_bbox[0][0]             \n",
      "                                                                 input_rpn_match[0][0]            \n",
      "                                                                 rpn_bbox[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "mrcnn_class_loss (Lambda)       ()                   0           proposal_targets[0][1]           \n",
      "                                                                 light_head_class_logits[0][0]    \n",
      "                                                                 lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "mrcnn_bbox_loss (Lambda)        ()                   0           proposal_targets[0][2]           \n",
      "                                                                 proposal_targets[0][1]           \n",
      "                                                                 light_head_bbox[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "mrcnn_mask_loss (Lambda)        ()                   0           proposal_targets[0][3]           \n",
      "                                                                 proposal_targets[0][1]           \n",
      "                                                                 mrcnn_mask[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 57,415,924\n",
      "Trainable params: 57,303,456\n",
      "Non-trainable params: 112,468\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# print the model summary\n",
    "model.keras_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-starting from epoch 243\n"
     ]
    }
   ],
   "source": [
    "# Load the weights\n",
    "model.load_weights(INIT_MODEL_PATH, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=14.16s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=4.43s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "train_dataset = coco.CocoDataset()\n",
    "train_dataset.load_coco(DEFAULT_COCO_PATH, \"train\", year=DEFAULT_DATASET_YEAR)\n",
    "train_dataset.prepare()\n",
    "val_dataset = coco.CocoDataset()\n",
    "val_dataset.load_coco(DEFAULT_COCO_PATH, \"val\", year=DEFAULT_DATASET_YEAR)\n",
    "val_dataset.prepare()\n",
    "\n",
    "# Image Augmentation\n",
    "# Right/Left flip 50% of the time\n",
    "augmentation = imgaug.augmenters.Fliplr(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting at epoch 243. LR=5e-05\n",
      "\n",
      "Checkpoint Path: /home/processyuan/code/HumanMask/my-Mobile-Mask-RCNN/logs/Light-Head/training20181211T1752/mask_rcnn_training_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "In model:  rpn_model\n",
      "In model:  large_separable_conv\n",
      "    light_head_large_separable_conv_0a   (Conv2D)\n",
      "    light_head_large_separable_conv_1a   (Conv2D)\n",
      "    light_head_large_separable_conv_0b   (Conv2D)\n",
      "    light_head_large_separable_conv_1b   (Conv2D)\n",
      "    light_head_large_separable_bn   (BatchNorm)\n",
      "light_head_class_conv   (TimeDistributed)\n",
      "light_head_class_bn    (TimeDistributed)\n",
      "light_head_bbox_fc     (TimeDistributed)\n",
      "light_head_class_logits   (TimeDistributed)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/processyuan/anaconda3/envs/tflite/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/home/processyuan/anaconda3/envs/tflite/lib/python3.6/site-packages/keras/engine/training_generator.py:47: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 244/391\n",
      "1000/1000 [==============================] - 1288s 1s/step - loss: 0.4901 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.2052 - mrcnn_bbox_loss: 0.2849 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.7013 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.2801 - val_mrcnn_bbox_loss: 0.4212 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 245/391\n",
      "1000/1000 [==============================] - 1236s 1s/step - loss: 0.5437 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.2279 - mrcnn_bbox_loss: 0.3157 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.7054 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.2563 - val_mrcnn_bbox_loss: 0.4492 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 246/391\n",
      "1000/1000 [==============================] - 1239s 1s/step - loss: 0.4868 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.1983 - mrcnn_bbox_loss: 0.2885 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 1.1299 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.5013 - val_mrcnn_bbox_loss: 0.6286 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 247/391\n",
      "1000/1000 [==============================] - 1232s 1s/step - loss: 0.4917 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.2121 - mrcnn_bbox_loss: 0.2797 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.8178 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.2549 - val_mrcnn_bbox_loss: 0.5630 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 248/391\n",
      "1000/1000 [==============================] - 1239s 1s/step - loss: 0.4991 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.2026 - mrcnn_bbox_loss: 0.2965 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.7233 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.2818 - val_mrcnn_bbox_loss: 0.4414 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 249/391\n",
      "1000/1000 [==============================] - 1236s 1s/step - loss: 0.5100 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.2213 - mrcnn_bbox_loss: 0.2888 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.7262 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.2332 - val_mrcnn_bbox_loss: 0.4930 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 250/391\n",
      "1000/1000 [==============================] - 1403s 1s/step - loss: 0.5201 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.2299 - mrcnn_bbox_loss: 0.2902 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.6352 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.2811 - val_mrcnn_bbox_loss: 0.3540 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 251/391\n",
      "1000/1000 [==============================] - 1232s 1s/step - loss: 0.5027 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.2171 - mrcnn_bbox_loss: 0.2856 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 1.1020 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.4989 - val_mrcnn_bbox_loss: 0.6031 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 252/391\n",
      "1000/1000 [==============================] - 1237s 1s/step - loss: 0.4686 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.1981 - mrcnn_bbox_loss: 0.2705 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.8232 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.3769 - val_mrcnn_bbox_loss: 0.4462 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 253/391\n",
      "1000/1000 [==============================] - 1237s 1s/step - loss: 0.4985 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.2225 - mrcnn_bbox_loss: 0.2760 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.7001 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.2499 - val_mrcnn_bbox_loss: 0.4502 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 254/391\n",
      "1000/1000 [==============================] - 1260s 1s/step - loss: 0.5229 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.2197 - mrcnn_bbox_loss: 0.3032 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.4848 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.1470 - val_mrcnn_bbox_loss: 0.3379 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 255/391\n",
      "1000/1000 [==============================] - 1239s 1s/step - loss: 0.5086 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.2203 - mrcnn_bbox_loss: 0.2882 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 1.6844 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.6063 - val_mrcnn_bbox_loss: 1.0781 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 256/391\n",
      "1000/1000 [==============================] - 1239s 1s/step - loss: 0.4994 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.2203 - mrcnn_bbox_loss: 0.2791 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.6340 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.2241 - val_mrcnn_bbox_loss: 0.4099 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 257/391\n",
      "1000/1000 [==============================] - 1235s 1s/step - loss: 0.5262 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.2347 - mrcnn_bbox_loss: 0.2914 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.8096 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.3197 - val_mrcnn_bbox_loss: 0.4899 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 258/391\n",
      "1000/1000 [==============================] - 1230s 1s/step - loss: 0.5289 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.2338 - mrcnn_bbox_loss: 0.2951 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.8062 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.2791 - val_mrcnn_bbox_loss: 0.5271 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 259/391\n",
      "1000/1000 [==============================] - 1248s 1s/step - loss: 0.5124 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.2238 - mrcnn_bbox_loss: 0.2886 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.6130 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.1582 - val_mrcnn_bbox_loss: 0.4549 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 260/391\n",
      "1000/1000 [==============================] - 1250s 1s/step - loss: 0.5237 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.2340 - mrcnn_bbox_loss: 0.2897 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.6764 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.2135 - val_mrcnn_bbox_loss: 0.4629 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 261/391\n",
      "1000/1000 [==============================] - 1241s 1s/step - loss: 0.5186 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.2343 - mrcnn_bbox_loss: 0.2844 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.6320 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.1650 - val_mrcnn_bbox_loss: 0.4669 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 262/391\n",
      "1000/1000 [==============================] - 1202s 1s/step - loss: 0.4838 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.2020 - mrcnn_bbox_loss: 0.2818 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.8854 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.2105 - val_mrcnn_bbox_loss: 0.6748 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 263/391\n",
      "1000/1000 [==============================] - 1235s 1s/step - loss: 0.4715 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.2008 - mrcnn_bbox_loss: 0.2707 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 1.1261 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.1702 - val_mrcnn_bbox_loss: 0.9560 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 264/391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1226s 1s/step - loss: 0.4806 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.2081 - mrcnn_bbox_loss: 0.2725 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.5857 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.1727 - val_mrcnn_bbox_loss: 0.4130 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 265/391\n",
      "1000/1000 [==============================] - 1222s 1s/step - loss: 0.4685 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.1937 - mrcnn_bbox_loss: 0.2748 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.7064 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.2537 - val_mrcnn_bbox_loss: 0.4527 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 266/391\n",
      "1000/1000 [==============================] - 1245s 1s/step - loss: 0.5291 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.2481 - mrcnn_bbox_loss: 0.2810 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.7705 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.2924 - val_mrcnn_bbox_loss: 0.4781 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 267/391\n",
      "1000/1000 [==============================] - 1232s 1s/step - loss: 0.4771 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.2119 - mrcnn_bbox_loss: 0.2652 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.8491 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.2923 - val_mrcnn_bbox_loss: 0.5569 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 268/391\n",
      "1000/1000 [==============================] - 1233s 1s/step - loss: 0.4707 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.2084 - mrcnn_bbox_loss: 0.2623 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 1.1449 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.6177 - val_mrcnn_bbox_loss: 0.5272 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 269/391\n",
      "1000/1000 [==============================] - 1243s 1s/step - loss: 0.5059 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.2247 - mrcnn_bbox_loss: 0.2813 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.8881 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.3622 - val_mrcnn_bbox_loss: 0.5260 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 270/391\n",
      "1000/1000 [==============================] - 1221s 1s/step - loss: 0.4502 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.1950 - mrcnn_bbox_loss: 0.2553 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.9256 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.4254 - val_mrcnn_bbox_loss: 0.5002 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 271/391\n",
      "1000/1000 [==============================] - 1228s 1s/step - loss: 0.5136 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.2289 - mrcnn_bbox_loss: 0.2847 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 1.9074 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.5377 - val_mrcnn_bbox_loss: 1.3697 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 272/391\n",
      "1000/1000 [==============================] - 1234s 1s/step - loss: 0.4954 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.2171 - mrcnn_bbox_loss: 0.2783 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.6419 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.2394 - val_mrcnn_bbox_loss: 0.4025 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 273/391\n",
      "1000/1000 [==============================] - 1238s 1s/step - loss: 0.4913 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.2130 - mrcnn_bbox_loss: 0.2783 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.5503 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.1446 - val_mrcnn_bbox_loss: 0.4057 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 274/391\n",
      "1000/1000 [==============================] - 1244s 1s/step - loss: 0.4365 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.1843 - mrcnn_bbox_loss: 0.2522 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.4658 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.1316 - val_mrcnn_bbox_loss: 0.3342 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 275/391\n",
      "1000/1000 [==============================] - 1287s 1s/step - loss: 0.4674 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.2085 - mrcnn_bbox_loss: 0.2589 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.8588 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.3402 - val_mrcnn_bbox_loss: 0.5186 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 276/391\n",
      "1000/1000 [==============================] - 1301s 1s/step - loss: 0.5016 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.2233 - mrcnn_bbox_loss: 0.2783 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.7176 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.2376 - val_mrcnn_bbox_loss: 0.4800 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 277/391\n",
      "1000/1000 [==============================] - 1268s 1s/step - loss: 0.4078 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.1664 - mrcnn_bbox_loss: 0.2414 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.9452 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.3634 - val_mrcnn_bbox_loss: 0.5817 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 278/391\n",
      "1000/1000 [==============================] - 1271s 1s/step - loss: 0.4350 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.1858 - mrcnn_bbox_loss: 0.2492 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.7705 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.2936 - val_mrcnn_bbox_loss: 0.4769 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 279/391\n",
      "1000/1000 [==============================] - 1294s 1s/step - loss: 0.5223 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.2431 - mrcnn_bbox_loss: 0.2792 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.6937 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.2153 - val_mrcnn_bbox_loss: 0.4784 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 280/391\n",
      "1000/1000 [==============================] - 1283s 1s/step - loss: 0.4903 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.2138 - mrcnn_bbox_loss: 0.2765 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.7580 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.2782 - val_mrcnn_bbox_loss: 0.4797 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 281/391\n",
      "1000/1000 [==============================] - 1287s 1s/step - loss: 0.4543 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.1883 - mrcnn_bbox_loss: 0.2660 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.8699 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.3073 - val_mrcnn_bbox_loss: 0.5626 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 282/391\n",
      "1000/1000 [==============================] - 1250s 1s/step - loss: 0.4210 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.1693 - mrcnn_bbox_loss: 0.2516 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.6486 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.2371 - val_mrcnn_bbox_loss: 0.4116 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 283/391\n",
      "1000/1000 [==============================] - 1259s 1s/step - loss: 0.4286 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.1803 - mrcnn_bbox_loss: 0.2483 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.7697 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.1752 - val_mrcnn_bbox_loss: 0.5945 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 284/391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1280s 1s/step - loss: 0.4952 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.2203 - mrcnn_bbox_loss: 0.2749 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.8070 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.2913 - val_mrcnn_bbox_loss: 0.5157 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 285/391\n",
      "1000/1000 [==============================] - 1289s 1s/step - loss: 0.5023 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.2303 - mrcnn_bbox_loss: 0.2719 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.8016 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.3257 - val_mrcnn_bbox_loss: 0.4759 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 286/391\n",
      "1000/1000 [==============================] - 1267s 1s/step - loss: 0.4427 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.1956 - mrcnn_bbox_loss: 0.2471 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.8823 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.4141 - val_mrcnn_bbox_loss: 0.4682 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 287/391\n",
      "1000/1000 [==============================] - 1266s 1s/step - loss: 0.4704 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.2053 - mrcnn_bbox_loss: 0.2652 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.9275 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.3718 - val_mrcnn_bbox_loss: 0.5556 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 288/391\n",
      "1000/1000 [==============================] - 1284s 1s/step - loss: 0.4624 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.2012 - mrcnn_bbox_loss: 0.2613 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 1.0118 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.4896 - val_mrcnn_bbox_loss: 0.5222 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 289/391\n",
      "1000/1000 [==============================] - 1259s 1s/step - loss: 0.4391 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.1900 - mrcnn_bbox_loss: 0.2491 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 1.6115 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.5285 - val_mrcnn_bbox_loss: 1.0829 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 290/391\n",
      "1000/1000 [==============================] - 1274s 1s/step - loss: 0.4491 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.1898 - mrcnn_bbox_loss: 0.2593 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.8396 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.2305 - val_mrcnn_bbox_loss: 0.6092 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 291/391\n",
      "1000/1000 [==============================] - 1275s 1s/step - loss: 0.4788 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.2133 - mrcnn_bbox_loss: 0.2654 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 1.0788 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.3854 - val_mrcnn_bbox_loss: 0.6934 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 292/391\n",
      "1000/1000 [==============================] - 1266s 1s/step - loss: 0.4326 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.1824 - mrcnn_bbox_loss: 0.2502 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.7164 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.2693 - val_mrcnn_bbox_loss: 0.4470 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 293/391\n",
      "1000/1000 [==============================] - 1274s 1s/step - loss: 0.4683 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.1948 - mrcnn_bbox_loss: 0.2735 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.6444 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.2061 - val_mrcnn_bbox_loss: 0.4383 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 294/391\n",
      "1000/1000 [==============================] - 1265s 1s/step - loss: 0.4271 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.1827 - mrcnn_bbox_loss: 0.2444 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.5301 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.1718 - val_mrcnn_bbox_loss: 0.3584 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 295/391\n",
      "1000/1000 [==============================] - 1273s 1s/step - loss: 0.4507 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.1931 - mrcnn_bbox_loss: 0.2576 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.8432 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.3156 - val_mrcnn_bbox_loss: 0.5276 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 296/391\n",
      "1000/1000 [==============================] - 1266s 1s/step - loss: 0.4785 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.2138 - mrcnn_bbox_loss: 0.2647 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.8025 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.2308 - val_mrcnn_bbox_loss: 0.5717 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 297/391\n",
      "1000/1000 [==============================] - 1269s 1s/step - loss: 0.4381 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.1803 - mrcnn_bbox_loss: 0.2577 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.7683 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.2619 - val_mrcnn_bbox_loss: 0.5064 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 298/391\n",
      "1000/1000 [==============================] - 1268s 1s/step - loss: 0.4672 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.2031 - mrcnn_bbox_loss: 0.2640 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.8068 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.3004 - val_mrcnn_bbox_loss: 0.5064 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 299/391\n",
      "1000/1000 [==============================] - 1275s 1s/step - loss: 0.4724 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.2080 - mrcnn_bbox_loss: 0.2643 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.8852 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.3806 - val_mrcnn_bbox_loss: 0.5047 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 300/391\n",
      "1000/1000 [==============================] - 1283s 1s/step - loss: 0.4429 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.1902 - mrcnn_bbox_loss: 0.2527 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 1.0252 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.4406 - val_mrcnn_bbox_loss: 0.5846 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 301/391\n",
      "1000/1000 [==============================] - 1275s 1s/step - loss: 0.4840 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.2080 - mrcnn_bbox_loss: 0.2760 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.9062 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.3937 - val_mrcnn_bbox_loss: 0.5125 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 302/391\n",
      "1000/1000 [==============================] - 1277s 1s/step - loss: 0.4960 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.2194 - mrcnn_bbox_loss: 0.2765 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.7978 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.3087 - val_mrcnn_bbox_loss: 0.4890 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 303/391\n",
      "1000/1000 [==============================] - 1289s 1s/step - loss: 0.5145 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.2324 - mrcnn_bbox_loss: 0.2820 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.8153 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.3357 - val_mrcnn_bbox_loss: 0.4796 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 304/391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1293s 1s/step - loss: 0.5650 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.2715 - mrcnn_bbox_loss: 0.2935 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.6265 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.2088 - val_mrcnn_bbox_loss: 0.4177 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 305/391\n",
      "1000/1000 [==============================] - 1222s 1s/step - loss: 0.4311 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.1882 - mrcnn_bbox_loss: 0.2430 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 1.0119 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.5100 - val_mrcnn_bbox_loss: 0.5018 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 306/391\n",
      "1000/1000 [==============================] - 1206s 1s/step - loss: 0.4704 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.1903 - mrcnn_bbox_loss: 0.2801 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.7593 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.2936 - val_mrcnn_bbox_loss: 0.4657 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 307/391\n",
      "1000/1000 [==============================] - 1203s 1s/step - loss: 0.4433 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.1847 - mrcnn_bbox_loss: 0.2586 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.6691 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.2467 - val_mrcnn_bbox_loss: 0.4224 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 308/391\n",
      "1000/1000 [==============================] - 1193s 1s/step - loss: 0.4562 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.2014 - mrcnn_bbox_loss: 0.2548 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.5717 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.1725 - val_mrcnn_bbox_loss: 0.3993 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 309/391\n",
      "1000/1000 [==============================] - 1394s 1s/step - loss: 0.4470 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.1897 - mrcnn_bbox_loss: 0.2574 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.7538 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.2824 - val_mrcnn_bbox_loss: 0.4714 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 310/391\n",
      "1000/1000 [==============================] - 2162s 2s/step - loss: 0.4791 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.2098 - mrcnn_bbox_loss: 0.2692 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.8122 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.3686 - val_mrcnn_bbox_loss: 0.4435 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 311/391\n",
      "1000/1000 [==============================] - 2160s 2s/step - loss: 0.4673 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.2089 - mrcnn_bbox_loss: 0.2585 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.7128 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.2652 - val_mrcnn_bbox_loss: 0.4476 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 312/391\n",
      "1000/1000 [==============================] - 1648s 2s/step - loss: 0.4499 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.1923 - mrcnn_bbox_loss: 0.2576 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 1.4666 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.4400 - val_mrcnn_bbox_loss: 1.0266 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 313/391\n",
      "1000/1000 [==============================] - 1471s 1s/step - loss: 0.4605 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.2075 - mrcnn_bbox_loss: 0.2530 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.8466 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.3747 - val_mrcnn_bbox_loss: 0.4719 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 314/391\n",
      "1000/1000 [==============================] - 1465s 1s/step - loss: 0.4226 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.1872 - mrcnn_bbox_loss: 0.2354 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.8370 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.2386 - val_mrcnn_bbox_loss: 0.5984 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 315/391\n",
      "1000/1000 [==============================] - 1470s 1s/step - loss: 0.4787 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.2123 - mrcnn_bbox_loss: 0.2664 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.9588 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.2250 - val_mrcnn_bbox_loss: 0.7338 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 316/391\n",
      "1000/1000 [==============================] - 1239s 1s/step - loss: 0.4742 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.2144 - mrcnn_bbox_loss: 0.2598 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 1.0446 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.5041 - val_mrcnn_bbox_loss: 0.5406 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 317/391\n",
      "1000/1000 [==============================] - 1231s 1s/step - loss: 0.4351 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.1848 - mrcnn_bbox_loss: 0.2503 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.6991 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.2178 - val_mrcnn_bbox_loss: 0.4813 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 318/391\n",
      "1000/1000 [==============================] - 1211s 1s/step - loss: 0.4293 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.1790 - mrcnn_bbox_loss: 0.2502 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 1.2703 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.4683 - val_mrcnn_bbox_loss: 0.8020 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 319/391\n",
      "1000/1000 [==============================] - 1219s 1s/step - loss: 0.4664 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.2060 - mrcnn_bbox_loss: 0.2604 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.6820 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.2222 - val_mrcnn_bbox_loss: 0.4597 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 320/391\n",
      "1000/1000 [==============================] - 1224s 1s/step - loss: 0.4659 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.2055 - mrcnn_bbox_loss: 0.2603 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.6550 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.2667 - val_mrcnn_bbox_loss: 0.3882 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 321/391\n",
      "1000/1000 [==============================] - 1222s 1s/step - loss: 0.4509 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.2000 - mrcnn_bbox_loss: 0.2509 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.8029 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.1824 - val_mrcnn_bbox_loss: 0.6205 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 322/391\n",
      "1000/1000 [==============================] - 1228s 1s/step - loss: 0.4495 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.1953 - mrcnn_bbox_loss: 0.2542 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.6854 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.2022 - val_mrcnn_bbox_loss: 0.4831 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 323/391\n",
      "1000/1000 [==============================] - 1216s 1s/step - loss: 0.4374 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.1944 - mrcnn_bbox_loss: 0.2430 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.9662 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.4356 - val_mrcnn_bbox_loss: 0.5306 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 324/391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1222s 1s/step - loss: 0.4463 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.1983 - mrcnn_bbox_loss: 0.2480 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 1.0608 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.4254 - val_mrcnn_bbox_loss: 0.6354 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 325/391\n",
      "1000/1000 [==============================] - 1226s 1s/step - loss: 0.4991 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.2284 - mrcnn_bbox_loss: 0.2708 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.6240 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.2726 - val_mrcnn_bbox_loss: 0.3515 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 326/391\n",
      "1000/1000 [==============================] - 1202s 1s/step - loss: 0.4343 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.1815 - mrcnn_bbox_loss: 0.2528 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.6912 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.2562 - val_mrcnn_bbox_loss: 0.4350 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 327/391\n",
      "1000/1000 [==============================] - 1210s 1s/step - loss: 0.4658 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.2127 - mrcnn_bbox_loss: 0.2531 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 3.2659 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 1.0529 - val_mrcnn_bbox_loss: 2.2130 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 328/391\n",
      "1000/1000 [==============================] - 1220s 1s/step - loss: 0.4806 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.2193 - mrcnn_bbox_loss: 0.2613 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.8944 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.3977 - val_mrcnn_bbox_loss: 0.4967 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 329/391\n",
      "1000/1000 [==============================] - 1184s 1s/step - loss: 0.4383 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.1864 - mrcnn_bbox_loss: 0.2520 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.7563 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.2908 - val_mrcnn_bbox_loss: 0.4655 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 330/391\n",
      "1000/1000 [==============================] - 1196s 1s/step - loss: 0.4469 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.1928 - mrcnn_bbox_loss: 0.2541 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.7289 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.3248 - val_mrcnn_bbox_loss: 0.4041 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 331/391\n",
      "1000/1000 [==============================] - 1228s 1s/step - loss: 0.4738 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.2192 - mrcnn_bbox_loss: 0.2546 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.6727 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.2623 - val_mrcnn_bbox_loss: 0.4104 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 332/391\n",
      "1000/1000 [==============================] - 1209s 1s/step - loss: 0.4098 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.1834 - mrcnn_bbox_loss: 0.2264 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.8455 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.3954 - val_mrcnn_bbox_loss: 0.4501 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 333/391\n",
      "1000/1000 [==============================] - 1211s 1s/step - loss: 0.4585 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.2048 - mrcnn_bbox_loss: 0.2537 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.7087 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.3716 - val_mrcnn_bbox_loss: 0.3371 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 334/391\n",
      "1000/1000 [==============================] - 1224s 1s/step - loss: 0.4552 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.1956 - mrcnn_bbox_loss: 0.2596 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.7195 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.3279 - val_mrcnn_bbox_loss: 0.3915 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 335/391\n",
      "1000/1000 [==============================] - 1198s 1s/step - loss: 0.4299 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.1838 - mrcnn_bbox_loss: 0.2462 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.8286 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.3500 - val_mrcnn_bbox_loss: 0.4786 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 336/391\n",
      "1000/1000 [==============================] - 1220s 1s/step - loss: 0.4604 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.2071 - mrcnn_bbox_loss: 0.2532 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.8189 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.3500 - val_mrcnn_bbox_loss: 0.4689 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 337/391\n",
      "1000/1000 [==============================] - 1206s 1s/step - loss: 0.4343 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.1833 - mrcnn_bbox_loss: 0.2509 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 1.1672 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.6287 - val_mrcnn_bbox_loss: 0.5385 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 338/391\n",
      "1000/1000 [==============================] - 1210s 1s/step - loss: 0.4474 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.1890 - mrcnn_bbox_loss: 0.2584 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.6308 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.2124 - val_mrcnn_bbox_loss: 0.4184 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 339/391\n",
      "1000/1000 [==============================] - 1204s 1s/step - loss: 0.4216 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.1829 - mrcnn_bbox_loss: 0.2387 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.6772 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.2677 - val_mrcnn_bbox_loss: 0.4095 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 340/391\n",
      "1000/1000 [==============================] - 1192s 1s/step - loss: 0.4432 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.1958 - mrcnn_bbox_loss: 0.2474 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 1.5183 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.4224 - val_mrcnn_bbox_loss: 1.0958 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 341/391\n",
      "1000/1000 [==============================] - 1213s 1s/step - loss: 0.4341 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.1899 - mrcnn_bbox_loss: 0.2442 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 1.7525 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.7507 - val_mrcnn_bbox_loss: 1.0019 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 342/391\n",
      "1000/1000 [==============================] - 1217s 1s/step - loss: 0.4671 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.2111 - mrcnn_bbox_loss: 0.2560 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.6640 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.2232 - val_mrcnn_bbox_loss: 0.4407 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 343/391\n",
      "1000/1000 [==============================] - 1203s 1s/step - loss: 0.4514 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.2039 - mrcnn_bbox_loss: 0.2476 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.6938 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.2646 - val_mrcnn_bbox_loss: 0.4292 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 344/391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1194s 1s/step - loss: 0.4362 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.1951 - mrcnn_bbox_loss: 0.2411 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.6891 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.2863 - val_mrcnn_bbox_loss: 0.4027 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 345/391\n",
      "1000/1000 [==============================] - 1204s 1s/step - loss: 0.4944 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.2239 - mrcnn_bbox_loss: 0.2704 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.7144 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.2206 - val_mrcnn_bbox_loss: 0.4939 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 346/391\n",
      "1000/1000 [==============================] - 1219s 1s/step - loss: 0.4319 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.1855 - mrcnn_bbox_loss: 0.2464 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.6298 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.2207 - val_mrcnn_bbox_loss: 0.4092 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 347/391\n",
      "1000/1000 [==============================] - 1209s 1s/step - loss: 0.4515 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.1944 - mrcnn_bbox_loss: 0.2571 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.7597 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.3372 - val_mrcnn_bbox_loss: 0.4225 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 348/391\n",
      "1000/1000 [==============================] - 1219s 1s/step - loss: 0.4794 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.2159 - mrcnn_bbox_loss: 0.2635 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.7768 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.3200 - val_mrcnn_bbox_loss: 0.4568 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 349/391\n",
      "1000/1000 [==============================] - 1184s 1s/step - loss: 0.4218 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.1729 - mrcnn_bbox_loss: 0.2489 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.8740 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.3773 - val_mrcnn_bbox_loss: 0.4967 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 350/391\n",
      "1000/1000 [==============================] - 1227s 1s/step - loss: 0.5190 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.2360 - mrcnn_bbox_loss: 0.2830 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.6835 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.2400 - val_mrcnn_bbox_loss: 0.4435 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 351/391\n",
      "1000/1000 [==============================] - 1220s 1s/step - loss: 0.4939 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.2213 - mrcnn_bbox_loss: 0.2727 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.7626 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.3168 - val_mrcnn_bbox_loss: 0.4458 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 352/391\n",
      "1000/1000 [==============================] - 1207s 1s/step - loss: 0.4548 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.2005 - mrcnn_bbox_loss: 0.2543 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.7751 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.3504 - val_mrcnn_bbox_loss: 0.4246 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 353/391\n",
      "1000/1000 [==============================] - 1204s 1s/step - loss: 0.4616 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.2080 - mrcnn_bbox_loss: 0.2536 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.7659 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.2948 - val_mrcnn_bbox_loss: 0.4711 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 354/391\n",
      "1000/1000 [==============================] - 1200s 1s/step - loss: 0.4130 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.1742 - mrcnn_bbox_loss: 0.2388 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 1.5096 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.5719 - val_mrcnn_bbox_loss: 0.9377 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 355/391\n",
      "1000/1000 [==============================] - 1196s 1s/step - loss: 0.4390 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.1925 - mrcnn_bbox_loss: 0.2464 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.7789 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.2815 - val_mrcnn_bbox_loss: 0.4974 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 356/391\n",
      "1000/1000 [==============================] - 1209s 1s/step - loss: 0.4467 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.1944 - mrcnn_bbox_loss: 0.2524 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.6839 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.2311 - val_mrcnn_bbox_loss: 0.4528 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 357/391\n",
      "1000/1000 [==============================] - 1212s 1s/step - loss: 0.4525 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.1945 - mrcnn_bbox_loss: 0.2580 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.8791 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.4295 - val_mrcnn_bbox_loss: 0.4496 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 358/391\n",
      "1000/1000 [==============================] - 1203s 1s/step - loss: 0.4622 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.2128 - mrcnn_bbox_loss: 0.2494 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.7674 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.3565 - val_mrcnn_bbox_loss: 0.4109 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 359/391\n",
      "1000/1000 [==============================] - 1214s 1s/step - loss: 0.4624 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.2117 - mrcnn_bbox_loss: 0.2507 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 1.2741 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.4121 - val_mrcnn_bbox_loss: 0.8620 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 360/391\n",
      "1000/1000 [==============================] - 1184s 1s/step - loss: 0.4173 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.1813 - mrcnn_bbox_loss: 0.2360 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.7273 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.2836 - val_mrcnn_bbox_loss: 0.4437 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 361/391\n",
      "1000/1000 [==============================] - 1191s 1s/step - loss: 0.4579 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.2104 - mrcnn_bbox_loss: 0.2475 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.8580 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.3799 - val_mrcnn_bbox_loss: 0.4781 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 362/391\n",
      "1000/1000 [==============================] - 1203s 1s/step - loss: 0.4130 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.1755 - mrcnn_bbox_loss: 0.2374 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.7642 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.3503 - val_mrcnn_bbox_loss: 0.4139 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 363/391\n",
      "1000/1000 [==============================] - 1219s 1s/step - loss: 0.5345 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.2429 - mrcnn_bbox_loss: 0.2916 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.6527 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.2706 - val_mrcnn_bbox_loss: 0.3821 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 364/391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1198s 1s/step - loss: 0.4476 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.2014 - mrcnn_bbox_loss: 0.2462 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.6648 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.2815 - val_mrcnn_bbox_loss: 0.3833 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 365/391\n",
      "1000/1000 [==============================] - 1204s 1s/step - loss: 0.4258 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.1868 - mrcnn_bbox_loss: 0.2390 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.7747 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.3177 - val_mrcnn_bbox_loss: 0.4570 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 366/391\n",
      "1000/1000 [==============================] - 1223s 1s/step - loss: 0.5075 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.2211 - mrcnn_bbox_loss: 0.2864 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.8156 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.3451 - val_mrcnn_bbox_loss: 0.4705 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 367/391\n",
      "1000/1000 [==============================] - 1205s 1s/step - loss: 0.4612 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.2101 - mrcnn_bbox_loss: 0.2511 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 1.6738 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.6340 - val_mrcnn_bbox_loss: 1.0399 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 368/391\n",
      "1000/1000 [==============================] - 1192s 1s/step - loss: 0.4348 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.1875 - mrcnn_bbox_loss: 0.2473 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.8157 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.2981 - val_mrcnn_bbox_loss: 0.5175 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 369/391\n",
      "1000/1000 [==============================] - 1221s 1s/step - loss: 0.4552 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.2023 - mrcnn_bbox_loss: 0.2529 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.7623 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.2975 - val_mrcnn_bbox_loss: 0.4648 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 370/391\n",
      "1000/1000 [==============================] - 1215s 1s/step - loss: 0.4985 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.2216 - mrcnn_bbox_loss: 0.2768 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 1.3278 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.5639 - val_mrcnn_bbox_loss: 0.7639 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 371/391\n",
      "1000/1000 [==============================] - 1197s 1s/step - loss: 0.4497 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.2033 - mrcnn_bbox_loss: 0.2464 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.7355 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.3185 - val_mrcnn_bbox_loss: 0.4170 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 372/391\n",
      "1000/1000 [==============================] - 1208s 1s/step - loss: 0.4509 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.1949 - mrcnn_bbox_loss: 0.2560 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.5711 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.1798 - val_mrcnn_bbox_loss: 0.3912 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 373/391\n",
      "1000/1000 [==============================] - 1221s 1s/step - loss: 0.5100 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.2301 - mrcnn_bbox_loss: 0.2799 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.6774 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.2181 - val_mrcnn_bbox_loss: 0.4593 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 374/391\n",
      "1000/1000 [==============================] - 1217s 1s/step - loss: 0.4684 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.1990 - mrcnn_bbox_loss: 0.2694 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.8154 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.3030 - val_mrcnn_bbox_loss: 0.5124 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 375/391\n",
      "1000/1000 [==============================] - 1208s 1s/step - loss: 0.4869 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.2216 - mrcnn_bbox_loss: 0.2653 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.6766 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.2317 - val_mrcnn_bbox_loss: 0.4449 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 376/391\n",
      "1000/1000 [==============================] - 1192s 1s/step - loss: 0.4143 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.1707 - mrcnn_bbox_loss: 0.2435 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.6630 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.1909 - val_mrcnn_bbox_loss: 0.4721 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 377/391\n",
      "1000/1000 [==============================] - 1205s 1s/step - loss: 0.4799 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.2191 - mrcnn_bbox_loss: 0.2608 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.5612 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.1681 - val_mrcnn_bbox_loss: 0.3930 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 378/391\n",
      "1000/1000 [==============================] - 1223s 1s/step - loss: 0.4723 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.2124 - mrcnn_bbox_loss: 0.2599 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.6508 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.2170 - val_mrcnn_bbox_loss: 0.4338 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 379/391\n",
      "1000/1000 [==============================] - 1226s 1s/step - loss: 0.4706 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.2086 - mrcnn_bbox_loss: 0.2621 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.6864 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.3188 - val_mrcnn_bbox_loss: 0.3675 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 380/391\n",
      "1000/1000 [==============================] - 1224s 1s/step - loss: 0.4864 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.2251 - mrcnn_bbox_loss: 0.2613 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.7426 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.2595 - val_mrcnn_bbox_loss: 0.4831 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 381/391\n",
      "1000/1000 [==============================] - 1209s 1s/step - loss: 0.4458 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.1918 - mrcnn_bbox_loss: 0.2540 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.6934 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.2482 - val_mrcnn_bbox_loss: 0.4452 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 382/391\n",
      "1000/1000 [==============================] - 1223s 1s/step - loss: 0.4526 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.2100 - mrcnn_bbox_loss: 0.2426 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 1.6644 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.7656 - val_mrcnn_bbox_loss: 0.8988 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 383/391\n",
      "1000/1000 [==============================] - 1205s 1s/step - loss: 0.4325 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.1947 - mrcnn_bbox_loss: 0.2378 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.6769 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.2532 - val_mrcnn_bbox_loss: 0.4237 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 384/391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1219s 1s/step - loss: 0.4691 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.2146 - mrcnn_bbox_loss: 0.2544 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.7488 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.3143 - val_mrcnn_bbox_loss: 0.4346 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 385/391\n",
      "1000/1000 [==============================] - 1203s 1s/step - loss: 0.4596 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.2035 - mrcnn_bbox_loss: 0.2560 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.7257 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.3134 - val_mrcnn_bbox_loss: 0.4123 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 386/391\n",
      "1000/1000 [==============================] - 1194s 1s/step - loss: 0.4014 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.1610 - mrcnn_bbox_loss: 0.2404 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.8959 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.3938 - val_mrcnn_bbox_loss: 0.5021 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 387/391\n",
      "1000/1000 [==============================] - 1242s 1s/step - loss: 0.4950 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.2215 - mrcnn_bbox_loss: 0.2735 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 1.3794 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.4608 - val_mrcnn_bbox_loss: 0.9186 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 388/391\n",
      "1000/1000 [==============================] - 1224s 1s/step - loss: 0.4713 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.2023 - mrcnn_bbox_loss: 0.2690 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.8279 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.3092 - val_mrcnn_bbox_loss: 0.5187 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 389/391\n",
      "1000/1000 [==============================] - 1234s 1s/step - loss: 0.4616 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.2069 - mrcnn_bbox_loss: 0.2547 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.8888 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.3907 - val_mrcnn_bbox_loss: 0.4981 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 390/391\n",
      "1000/1000 [==============================] - 1226s 1s/step - loss: 0.4888 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.2207 - mrcnn_bbox_loss: 0.2680 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.8649 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.3542 - val_mrcnn_bbox_loss: 0.5107 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 391/391\n",
      "1000/1000 [==============================] - 1214s 1s/step - loss: 0.4589 - rpn_class_loss: 0.0000e+00 - rpn_bbox_loss: 0.0000e+00 - mrcnn_class_loss: 0.2106 - mrcnn_bbox_loss: 0.2483 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 0.7844 - val_rpn_class_loss: 0.0000e+00 - val_rpn_bbox_loss: 0.0000e+00 - val_mrcnn_class_loss: 0.3151 - val_mrcnn_bbox_loss: 0.4693 - val_mrcnn_mask_loss: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "# # # layers: \"heads\", \"5+\", \"4+\", \"3+\", \"all\", \"light-head\"\n",
    "model.train(train_dataset=train_dataset,\n",
    "                val_dataset=val_dataset,\n",
    "                learning_rate=config.LEARNING_RATE / 20.0,\n",
    "                epochs=391,\n",
    "                layers='light-head-detection',\n",
    "                augmentation=augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refer to the trained ResNet-101-based Mask-RCNN, loss should be \n",
    "# Epoch 1/30\n",
    "#  28/1000 [..............................] - ETA: 1:37:39 \n",
    "# - loss: 0.6337 \n",
    "# - rpn_class_loss: 0.0112 \n",
    "# - rpn_bbox_loss: 0.1044 \n",
    "# - mrcnn_class_loss: 0.2009 \n",
    "# - mrcnn_bbox_loss: 0.0904 \n",
    "# - mrcnn_mask_loss: 0.2268"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
